#!/usr/bin/env python3

import jax
import jax.numpy as jnp 
from jax.flatten_util import ravel_pytree
import optax
import os
import multiprocessing
import math
import pandas as pd
import numpy as np 
import ast
from typing import List, Tuple

# å¯¼å…¥æ‰€éœ€çš„æ¨¡å—
from crystalformer.src.utils import GLXYZAW_from_file, letter_to_number
from crystalformer.src.elements import element_dict, element_list
from crystalformer.src.transformer import make_transformer  
from crystalformer.src.sample import sample_crystal
from crystalformer.src.loss import make_loss_fn
import crystalformer.src.checkpoint as checkpoint
from crystalformer.src.wyckoff import mult_table

class BatchSampler:
    def __init__(self, restore_path: str):
        """åˆå§‹åŒ–æ‰¹é‡é‡‡æ ·å™¨"""
        print("æ­£åœ¨åˆå§‹åŒ–æ‰¹é‡é‡‡æ ·å™¨...")
        
        # å›ºå®šå‚æ•° (ä»åŸå§‹å‘½ä»¤ä¸­æå–)
        self.args = self.create_args()
        
        # åˆå§‹åŒ–éšæœºæ•°ç§å­
        self.key = jax.random.PRNGKey(42)
        
        # å¯ç”¨x64ç²¾åº¦
        jax.config.update("jax_enable_x64", True)
        
        print("æ­£åœ¨åˆ›å»ºtransformer...")
        # åˆ›å»ºtransformer (æ³¨æ„æ­£ç¡®çš„å‚æ•°é¡ºåº)
        self.params, self.transformer = make_transformer(
            self.key, self.args.Nf, self.args.Kx, self.args.Kl, self.args.n_max, 
            self.args.h0_size, 
            self.args.transformer_layers, self.args.num_heads, 
            self.args.key_size, self.args.model_size, self.args.embed_size, 
            self.args.atom_types, self.args.wyck_types,
            self.args.dropout_rate, self.args.attn_dropout,
            use_comp_feature=self.args.use_comp_feature,
            comp_feature_dim=self.args.comp_feature_dim,
            use_xrd_feature=self.args.use_xrd_feature,
            xrd_feature_dim=self.args.xrd_feature_dim
        )
        
        print("æ­£åœ¨åŠ è½½checkpoint...")
        # åŠ è½½checkpoint (è¦†ç›–åˆå§‹å‚æ•°)
        ckpt_filename, epoch_finished = checkpoint.find_ckpt_filename(restore_path)
        ckpt = checkpoint.load_data(ckpt_filename)
        self.params = ckpt["params"]
        
        # åˆ›å»ºæŸå¤±å‡½æ•° (æ³¨æ„æ­£ç¡®çš„å‚æ•°é¡ºåº)
        self.loss_fn, self.logp_fn = make_loss_fn(
            self.args.n_max, self.args.atom_types, self.args.wyck_types, self.args.Kx, self.args.Kl, 
            self.transformer, self.args.lamb_a, self.args.lamb_w, self.args.lamb_l, 
            self.args.use_comp_feature, self.args.use_xrd_feature
        )
        
        # é¢„è®¡ç®—ä¸€äº›mask (æŒ‰ç…§main.pyçš„æ–¹å¼)
        # w_mask - ç”¨äºWyckoffä½ç½®çº¦æŸï¼Œæˆ‘ä»¬ä¸æŒ‡å®šç‰¹å®šçš„Wyckoffä½ç½®ï¼Œæ‰€ä»¥è®¾ä¸ºNone
        self.w_mask = None
        
        # atom_mask - ç”¨äºå…ƒç´ ç±»å‹çº¦æŸ
        radioactive_element = [43, 61, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]
        noble_gas = [2, 10, 18, 36, 54, 86]
        
        if self.args.remove_radioactive:
            remove_list = radioactive_element + noble_gas
        else:
            remove_list = []
        
        # åˆ›å»ºatom_maskï¼šæ¯ä¸ªåŸå­ä½ç½®éƒ½æœ‰ä¸€ä¸ªmask (shape: n_max, atom_types)
        base_mask = jnp.ones(self.args.atom_types, dtype=int)
        if remove_list:
            base_mask = base_mask.at[remove_list].set(0)
        self.atom_mask = jnp.stack([base_mask] * self.args.n_max, axis=0)
        
        print("âœ“ æ‰¹é‡é‡‡æ ·å™¨åˆå§‹åŒ–å®Œæˆï¼")
    
    def create_args(self):
        """åˆ›å»ºå‚æ•°å¯¹è±¡"""
        class Args:
            def __init__(self):
                # æ¨¡å‹å‚æ•°
                self.atom_types = 119
                self.wyck_types = 28
                self.n_max = 21
                self.Nf = 5
                self.Kx = 16
                self.Kl = 16
                self.h0_size = 256
                self.transformer_layers = 16
                self.num_heads = 8
                self.key_size = 64
                self.model_size = 32
                self.embed_size = 32
                self.dropout_rate = 0.4
                self.attn_dropout = 0.4
                
                # æŸå¤±å‚æ•°
                self.lamb_a = 1.0
                self.lamb_w = 1.0
                self.lamb_l = 1.0
                
                # é‡‡æ ·å‚æ•°
                self.batchsize = 30  # å¢åŠ åˆ°30ï¼Œæ¯è¡Œåªéœ€1ä¸ªæ‰¹æ¬¡
                self.temperature = 1.0
                self.top_p = 1.0
                self.remove_radioactive = False
                
                # ç»„æˆç‰¹å¾å‚æ•°
                self.use_comp_feature = True
                self.comp_feature_dim = 256
                
                # XRDç‰¹å¾å‚æ•°
                self.use_xrd_feature = False
                self.xrd_feature_dim = 1080
        
        return Args()
    
    def generate_composition_features(self, csv_path: str, data_index: int):
        """ç”Ÿæˆç»„æˆç‰¹å¾"""
        if csv_path is not None and os.path.exists(csv_path):
            try:
                df = pd.read_csv(csv_path)
                
                if data_index >= len(df):
                    print(f"è­¦å‘Š: data_index {data_index} >= æ•°æ®é›†å¤§å° {len(df)}, ä½¿ç”¨æœ€åä¸€è¡Œ")
                    data_index = len(df) - 1
                
                # ä»ç¬¬10åˆ—å¼€å§‹è¯»å–256ç»´ç»„æˆç‰¹å¾
                comp_features = df.iloc[data_index, 9:9+self.args.comp_feature_dim].values
                comp_features = np.array(comp_features, dtype=np.float32)
                
                # è¯»å–mp-id (ç¬¬2åˆ—, ç´¢å¼•ä¸º1)
                mp_id = df.iloc[data_index, 1]
                
                return jnp.array(comp_features), str(mp_id)
                
            except Exception as e:
                print(f"åŠ è½½ç»„æˆç‰¹å¾æ—¶å‡ºé”™: {e}")
        
        # å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
        return jnp.array(np.random.normal(0, 0.1, self.args.comp_feature_dim), dtype=jnp.float32), "mock-mp-id"
    
    def generate_xrd_features(self, csv_path: str, data_index: int):
        """ç”ŸæˆXRDç‰¹å¾"""
        if csv_path is not None and os.path.exists(csv_path) and 'xrd' in csv_path:
            try:
                df = pd.read_csv(csv_path)
                
                if data_index >= len(df):
                    print(f"è­¦å‘Š: data_index {data_index} >= æ•°æ®é›†å¤§å° {len(df)}, ä½¿ç”¨æœ€åä¸€è¡Œ")
                    data_index = len(df) - 1
                
                if 'xrd_data' in df.columns:
                    # è¯»å–XRDæ•°æ®ï¼ˆé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼‰
                    xrd_str = df.iloc[data_index]['xrd_data']
                    xrd_values = [float(x) for x in xrd_str.split(',')]
                    xrd_features = np.array(xrd_values, dtype=np.float32)
                    
                    if len(xrd_features) == self.args.xrd_feature_dim:
                        return jnp.array(xrd_features)
                    else:
                        print(f"è­¦å‘Š: XRDç‰¹å¾ç»´åº¦ä¸åŒ¹é… ({len(xrd_features)} vs {self.args.xrd_feature_dim})")
                        
            except Exception as e:
                print(f"åŠ è½½XRDç‰¹å¾æ—¶å‡ºé”™: {e}")
        
        # å›é€€åˆ°é›¶å‘é‡ï¼ˆåœ¨ç”Ÿæˆæ–°ç»“æ„æ—¶ï¼Œé€šå¸¸æ²¡æœ‰ç›®æ ‡XRDï¼‰
        return jnp.zeros(self.args.xrd_feature_dim, dtype=jnp.float32)
    
    def sample_single_row(self, row_index: int, mp_id: str, elements: List[str], 
                         spacegroup: int, num_samples: int, csv_path: str):
        """ä¸ºå•è¡Œæ•°æ®ç”Ÿæˆæ ·æœ¬"""
        print(f"\næ­£åœ¨ä¸ºç¬¬{row_index}è¡Œç”Ÿæˆæ ·æœ¬...")
        print(f"  mp_id: {mp_id}")
        print(f"  elements: {elements}")
        print(f"  spacegroup: {spacegroup}")
        print(f"  æ ·æœ¬æ•°: {num_samples}")
        
        # ç”Ÿæˆç»„æˆç‰¹å¾
        composition_features, loaded_mp_id = self.generate_composition_features(csv_path, row_index)
        
        # ç”ŸæˆXRDç‰¹å¾
        xrd_features = self.generate_xrd_features(csv_path, row_index) if self.args.use_xrd_feature else None
        
        # ä½ç½®çº¦æŸ (æŒ‰ç…§main.pyçš„æ–¹å¼) - è¿™ä¸æ˜¯å…ƒç´ çº¦æŸï¼
        constraints = jnp.arange(0, self.args.n_max, 1)
        
        # å…ƒç´ çº¦æŸé€šè¿‡ä¿®æ”¹atom_maskå®ç°
        if elements:
            element_numbers = [letter_to_number(e) for e in elements]
            # åˆ›å»ºåªå…è®¸ç‰¹å®šå…ƒç´ çš„atom_mask
            base_constraints = jnp.zeros(self.args.atom_types, dtype=int)
            base_constraints = base_constraints.at[tuple(element_numbers)].set(1)
            atom_mask = jnp.stack([base_constraints] * self.args.n_max, axis=0)
        else:
            atom_mask = self.atom_mask
        
        # æ‰¹é‡ç”Ÿæˆæ ·æœ¬
        all_samples = []
        num_batches = math.ceil(num_samples / self.args.batchsize)
        
        for batch_idx in range(num_batches):
            start_idx = batch_idx * self.args.batchsize
            end_idx = min(start_idx + self.args.batchsize, num_samples)
            n_sample = end_idx - start_idx
            
            # åˆ†å‰²éšæœºæ•°ç§å­
            self.key, subkey = jax.random.split(self.key)
            
            print(f"  æ‰¹æ¬¡ {batch_idx + 1}/{num_batches}: ç”Ÿæˆ {n_sample} ä¸ªæ ·æœ¬...")
            
            # ç”Ÿæˆæ ·æœ¬
            XYZ, A, W, M, L = sample_crystal(
                subkey, self.transformer, self.params, self.args.n_max, n_sample, 
                self.args.atom_types, self.args.wyck_types, self.args.Kx, self.args.Kl, 
                spacegroup, self.w_mask, atom_mask, self.args.top_p, self.args.temperature, 
                self.args.temperature, constraints, composition_features, xrd_features
            )
            
            # å‡†å¤‡æ•°æ®
            batch_data = pd.DataFrame()
            batch_data['L'] = np.array(L).tolist()
            batch_data['X'] = np.array(XYZ).tolist()
            batch_data['A'] = np.array(A).tolist()
            batch_data['W'] = np.array(W).tolist()
            batch_data['M'] = np.array(M).tolist()
            batch_data['mp_id'] = [mp_id] * n_sample
            batch_data['source_row'] = [row_index] * n_sample
            batch_data['spacegroup'] = [spacegroup] * n_sample
            batch_data['elements'] = [str(elements)] * n_sample
            
            # è®¡ç®—logæ¦‚ç‡
            num_atoms = jnp.sum(M, axis=1)
            length, angle = jnp.split(L, 2, axis=-1)
            length = length/num_atoms[:, None]**(1/3)
            angle = angle * (jnp.pi / 180)  # è½¬æ¢ä¸ºå¼§åº¦
            L_normalized = jnp.concatenate([length, angle], axis=-1)
            
            G = spacegroup * jnp.ones((n_sample), dtype=int)
            
            # æ ¹æ®ç‰¹å¾é…ç½®è°ƒç”¨ä¸åŒçš„logp_fn
            if self.args.use_comp_feature and self.args.use_xrd_feature:
                # ä¸¤ç§ç‰¹å¾éƒ½ä½¿ç”¨
                batch_comp_features = jnp.tile(composition_features[None, :], (n_sample, 1))
                batch_xrd_features = jnp.tile(xrd_features[None, :], (n_sample, 1))
                logp_w, logp_xyz, logp_a, logp_l = jax.jit(self.logp_fn, static_argnums=7)(
                    self.params, subkey, G, L_normalized, XYZ, A, W, False, batch_comp_features, batch_xrd_features
                )
            elif self.args.use_comp_feature:
                # åªä½¿ç”¨compositionç‰¹å¾
                batch_comp_features = jnp.tile(composition_features[None, :], (n_sample, 1))
                logp_w, logp_xyz, logp_a, logp_l = jax.jit(self.logp_fn, static_argnums=7)(
                    self.params, subkey, G, L_normalized, XYZ, A, W, False, batch_comp_features
                )
            else:
                # ä¸ä½¿ç”¨é¢å¤–ç‰¹å¾
                logp_w, logp_xyz, logp_a, logp_l = jax.jit(self.logp_fn, static_argnums=7)(
                    self.params, subkey, G, L_normalized, XYZ, A, W, False
                )
            
            batch_data['logp_w'] = np.array(logp_w).tolist()
            batch_data['logp_xyz'] = np.array(logp_xyz).tolist()
            batch_data['logp_a'] = np.array(logp_a).tolist()
            batch_data['logp_l'] = np.array(logp_l).tolist()
            batch_data['logp'] = np.array(logp_xyz + self.args.lamb_w*logp_w + 
                                         self.args.lamb_a*logp_a + self.args.lamb_l*logp_l).tolist()
            
            all_samples.append(batch_data)
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
        if all_samples:
            result_data = pd.concat(all_samples, ignore_index=True)
            result_data = result_data.sort_values(by='logp', ascending=False)
            print(f"  âœ“ æˆåŠŸç”Ÿæˆ {len(result_data)} ä¸ªæ ·æœ¬")
            return result_data
        else:
            print(f"  âœ— ç”Ÿæˆæ ·æœ¬å¤±è´¥")
            return None

def extract_csv_data(csv_path: str, num_rows: int = 10) -> List[Tuple[int, str, List[str], int]]:
    """ä»CSVæ–‡ä»¶ä¸­æå–æ•°æ®"""
    print(f"æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {csv_path}")
    df = pd.read_csv(csv_path)
    
    results = []
    for i in range(min(num_rows, len(df))):
        row = df.iloc[i]
        
        # è·å–mp_id (ç¬¬2åˆ—ï¼Œç´¢å¼•1)
        mp_id = row.iloc[1]
        
        # è·å–elements (ç¬¬7åˆ—ï¼Œç´¢å¼•6)
        elements_str = row.iloc[6]
        try:
            elements_list = ast.literal_eval(elements_str)
        except:
            print(f"è­¦å‘Šï¼šæ— æ³•è§£æç¬¬{i}è¡Œçš„elements: {elements_str}")
            continue
            
        # è·å–spacegroup.number (ç¬¬9åˆ—ï¼Œç´¢å¼•8)
        spacegroup_number = int(row.iloc[8])
        
        results.append((i, mp_id, elements_list, spacegroup_number))
        print(f"ç¬¬{i}è¡Œ: mp_id={mp_id}, elements={elements_list}, spacegroup={spacegroup_number}")
    
    return results

def main():
    # é…ç½®å‚æ•°
    CSV_PATH = "data/test_comp_cleaned_xrd.csv"  # ä½¿ç”¨åŒ…å«XRDæ•°æ®çš„æ–‡ä»¶
    NUM_ROWS = 1000
    SAMPLES_PER_ROW = 30
    RESTORE_PATH = "test_output/adam_bs_90_lr_0.0005_decay_0_clip_1_A_119_W_28_N_21_a_1_w_1_l_1_Nf_5_Kx_16_Kl_16_h0_256_l_16_H_8_k_64_m_32_e_32_drop_0.4_0.4"
    OUTPUT_FILE = "test_output/batch_samples_1000rows_fast_comp_only.csv"
    
    print("å¼€å§‹é«˜é€Ÿæ‰¹é‡é‡‡æ ·...")
    print(f"CSVæ–‡ä»¶: {CSV_PATH}")
    print(f"å¤„ç†è¡Œæ•°: {NUM_ROWS}")
    print(f"æ¯è¡Œæ ·æœ¬æ•°: {SAMPLES_PER_ROW}")
    print(f"æ¨¡å‹è·¯å¾„: {RESTORE_PATH}")
    print("=" * 80)
    
    # 1. æå–CSVæ•°æ®
    csv_data = extract_csv_data(CSV_PATH, NUM_ROWS)
    
    if not csv_data:
        print("âœ— æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„CSVæ•°æ®")
        return
    
    print(f"\næˆåŠŸæå– {len(csv_data)} è¡Œæ•°æ®")
    print("=" * 80)
    
    # 2. åˆå§‹åŒ–æ‰¹é‡é‡‡æ ·å™¨ (åªéœ€è¦ä¸€æ¬¡!)
    try:
        sampler = BatchSampler(RESTORE_PATH)
    except Exception as e:
        print(f"âœ— åˆå§‹åŒ–é‡‡æ ·å™¨å¤±è´¥: {e}")
        return
    
    print("=" * 80)
    
    # 3. å¾ªç¯å¤„ç†æ¯è¡Œæ•°æ®
    all_results = []
    total_start_time = pd.Timestamp.now()
    
    for row_index, mp_id, elements, spacegroup in csv_data:
        start_time = pd.Timestamp.now()
        
        result_data = sampler.sample_single_row(
            row_index, mp_id, elements, spacegroup, SAMPLES_PER_ROW, CSV_PATH
        )
        
        if result_data is not None:
            all_results.append(result_data)
            
        elapsed = (pd.Timestamp.now() - start_time).total_seconds()
        print(f"  è¡Œ {row_index} è€—æ—¶: {elapsed:.2f}ç§’")
    
    # 4. åˆå¹¶æ‰€æœ‰ç»“æœ
    if all_results:
        final_data = pd.concat(all_results, ignore_index=True)
        final_data.to_csv(OUTPUT_FILE, index=False)
        
        total_elapsed = (pd.Timestamp.now() - total_start_time).total_seconds()
        
        print("=" * 80)
        print(f"ğŸ‰ æ‰¹é‡é‡‡æ ·å®Œæˆï¼")
        print(f"æœ€ç»ˆç»“æœä¿å­˜åœ¨: {OUTPUT_FILE}")
        print(f"æ€»å…±ç”Ÿæˆäº† {len(final_data)} ä¸ªæ ·æœ¬")
        print(f"æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
        print(f"å¹³å‡æ¯è¡Œè€—æ—¶: {total_elapsed/len(csv_data):.2f}ç§’")
        print(f"å¹³å‡æ¯ä¸ªæ ·æœ¬è€—æ—¶: {total_elapsed/(len(csv_data)*SAMPLES_PER_ROW):.3f}ç§’")
    else:
        print("\nâŒ æ‰€æœ‰è¡Œçš„é‡‡æ ·éƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    main() 